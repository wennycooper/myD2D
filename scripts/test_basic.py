#!/usr/bin/env python3
"""
Basic Test Script for Hybrid Anomaly Detection
æ¸¬è©¦åŸºæœ¬åŠŸèƒ½çš„è…³æœ¬ï¼Œä¸ä¾è³´å®Œæ•´çš„D2Då’ŒAnomalyCLIPç’°å¢ƒ
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append('/home/kkuei/my-proj')

def test_config():
    """æ¸¬è©¦é…ç½®æ¨¡çµ„"""
    print("Testing configuration module...")
    
    try:
        from config.base_config import get_default_config, get_debug_config
        
        # æ¸¬è©¦é è¨­é…ç½®
        config = get_default_config()
        print(f"âœ“ Default config loaded")
        print(f"  Model n_ctx: {config.model.n_ctx}")
        print(f"  Training epochs: {config.training.epochs}")
        print(f"  Data path: {config.data.data_path}")
        
        # æ¸¬è©¦debugé…ç½®
        debug_config = get_debug_config()
        print(f"âœ“ Debug config loaded")
        print(f"  Debug epochs: {debug_config.training.epochs}")
        
        # æ¸¬è©¦ä¿å­˜å’Œè¼‰å…¥
        test_path = "/tmp/test_config.json"
        config.save(test_path)
        loaded_config = config.load(test_path)
        print("âœ“ Config save/load test passed")
        
        # æ¸…ç†
        os.remove(test_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ Config test failed: {e}")
        return False


def test_prompt_learner():
    """æ¸¬è©¦prompt learneræ¨¡çµ„"""
    print("\nTesting prompt learner module...")
    
    try:
        from models.prompt_learner import MinimalPromptLearner
        
        # å‰µå»ºmock text encoder
        class MockTextEncoder:
            def __init__(self):
                self.config = type('Config', (), {'hidden_size': 768})()
                self.tokenizer = self.MockTokenizer()
                
            class MockTokenizer:
                def __call__(self, text, **kwargs):
                    return type('TokenizerOutput', (), {
                        'input_ids': torch.randint(0, 1000, (1, 77))
                    })()
                    
            def get_input_embeddings(self):
                return nn.Embedding(1000, 768)
        
        # æ¸¬è©¦prompt learner
        mock_encoder = MockTextEncoder()
        design_details = {
            "Prompt_length": 12,
            "learnabel_text_embedding_depth": 9,
            "learnabel_text_embedding_length": 4
        }
        
        prompt_learner = MinimalPromptLearner(mock_encoder, design_details)
        
        # æ¸¬è©¦forward pass
        normal_prompt, abnormal_prompt, compound_prompts = prompt_learner()
        
        print(f"âœ“ Prompt learner created")
        print(f"  Normal prompt shape: {normal_prompt.shape}")
        print(f"  Abnormal prompt shape: {abnormal_prompt.shape}")
        print(f"  Compound prompts: {len(compound_prompts)}")
        
        # æ¸¬è©¦åƒæ•¸ç²å–
        params = prompt_learner.get_learnable_parameters()
        total_params = sum(p.numel() for p in params)
        print(f"  Learnable parameters: {total_params:,}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Prompt learner test failed: {e}")
        return False


def test_loss_functions():
    """æ¸¬è©¦losså‡½æ•¸"""
    print("\nTesting loss functions...")
    
    try:
        from losses.hybrid_loss import CrossAttentionLoss
        
        # å‰µå»ºdummy data
        batch_size = 2
        h, w = 64, 64
        
        predictions = {
            'normal_attention': torch.randn(batch_size, h, w),
            'abnormal_attention': torch.randn(batch_size, h, w),
            'prompt_embeddings': {
                'normal': torch.randn(1, 77, 768),
                'abnormal': torch.randn(1, 77, 768)
            }
        }
        
        targets = {
            'masks': torch.randint(0, 2, (batch_size, h, w)).float(),
            'labels': torch.randint(0, 2, (batch_size,))
        }
        
        # æ¸¬è©¦lossè¨ˆç®—
        loss_fn = CrossAttentionLoss()
        total_loss, loss_dict = loss_fn(predictions, targets)
        
        print(f"âœ“ Loss functions working")
        print(f"  Total loss: {total_loss.item():.4f}")
        print(f"  Loss components: {len(loss_dict)}")
        
        # æ¸¬è©¦backward pass
        total_loss.backward()
        print("âœ“ Backward pass successful")
        
        return True
        
    except Exception as e:
        print(f"âŒ Loss function test failed: {e}")
        return False


def test_model_components():
    """æ¸¬è©¦æ¨¡å‹çµ„ä»¶ (ä¸éœ€è¦å®Œæ•´D2Dç’°å¢ƒ)"""
    print("\nTesting model components...")
    
    try:
        # åªæ¸¬è©¦prompt learneréƒ¨åˆ†
        from models.prompt_learner import MinimalPromptLearner
        
        # Mock text encoder
        class MockTextEncoder:
            def __init__(self):
                self.config = type('Config', (), {'hidden_size': 768})()
                self.tokenizer = self.MockTokenizer()
                
            class MockTokenizer:
                def __call__(self, text, **kwargs):
                    return type('TokenizerOutput', (), {
                        'input_ids': torch.randint(0, 1000, (1, 77))
                    })()
                    
            def get_input_embeddings(self):
                return nn.Embedding(1000, 768)
        
        mock_encoder = MockTextEncoder()
        prompt_learner = MinimalPromptLearner(mock_encoder, {
            "Prompt_length": 12,
            "learnabel_text_embedding_depth": 9,
            "learnabel_text_embedding_length": 4
        })
        
        # æ¸¬è©¦è¨“ç·´æ¨¡å¼
        prompt_learner.train()
        normal_prompt, abnormal_prompt, compound_prompts = prompt_learner()
        
        # æ¸¬è©¦optimizerèƒ½å¤ å·¥ä½œ
        optimizer = torch.optim.Adam(prompt_learner.get_learnable_parameters(), lr=1e-3)
        
        # å‰µå»ºdummy lossä¸¦æ¸¬è©¦backward
        dummy_loss = torch.sum(normal_prompt) + torch.sum(abnormal_prompt)
        optimizer.zero_grad()
        dummy_loss.backward()
        optimizer.step()
        
        print("âœ“ Model components basic test passed")
        
        return True
        
    except Exception as e:
        print(f"âŒ Model components test failed: {e}")
        return False


def test_training_script():
    """æ¸¬è©¦è¨“ç·´è…³æœ¬çš„åŸºæœ¬import"""
    print("\nTesting training script imports...")
    
    try:
        # å˜—è©¦import trainingç›¸é—œæ¨¡çµ„
        from config.base_config import get_debug_config
        from losses.hybrid_loss import CrossAttentionLoss
        
        # å‰µå»ºdebugé…ç½®
        config = get_debug_config()
        print(f"âœ“ Training configuration ready")
        print(f"  Debug epochs: {config.training.epochs}")
        print(f"  Batch size: {config.training.batch_size}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Training script test failed: {e}")
        return False


def main():
    """é‹è¡Œæ‰€æœ‰åŸºæœ¬æ¸¬è©¦"""
    print("=== Hybrid Anomaly Detection Basic Tests ===")
    
    tests = [
        ("Configuration", test_config),
        ("Prompt Learner", test_prompt_learner),
        ("Loss Functions", test_loss_functions),
        ("Model Components", test_model_components),
        ("Training Script", test_training_script),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"Running {test_name} Test")
        print('='*50)
        
        success = test_func()
        results.append((test_name, success))
    
    # ç¸½çµçµæœ
    print("\n" + "="*50)
    print("TEST SUMMARY")
    print("="*50)
    
    passed = 0
    for test_name, success in results:
        status = "âœ“ PASS" if success else "âŒ FAIL"
        print(f"{test_name:20} : {status}")
        if success:
            passed += 1
    
    print(f"\nPassed: {passed}/{len(results)} tests")
    
    if passed == len(results):
        print("\nğŸ‰ All basic tests passed! Ready for full implementation.")
    else:
        print(f"\nâš ï¸  {len(results) - passed} tests failed. Please check the issues above.")
    
    return passed == len(results)


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)